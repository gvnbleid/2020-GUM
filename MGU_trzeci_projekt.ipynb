{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MGU_trzeci_projekt.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gvnbleid/2020-GUM/blob/master/MGU_trzeci_projekt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5k5hvAQCjzZ",
        "colab_type": "text"
      },
      "source": [
        "Pobieranie danych z Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2g17D-djVnH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir .kaggle\n",
        "!mkdir /root/.kaggle\n",
        "import json\n",
        "token = {\"username\":\"jacekmyna\",\"key\":\"7eff50cbfe2c482b7125064101dc821d\"}\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)\n",
        "!chmod 600 /content/.kaggle/kaggle.json\n",
        "!cp /content/.kaggle/kaggle.json /root/.kaggle/kaggle.json\n",
        "!kaggle config set -n path -v{/content}\n",
        "!kaggle competitions download -c tensorflow-speech-recognition-challenge -p /content\n",
        "!7z x train.7z -o/content/data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3Mnr24fCn5n",
        "colab_type": "text"
      },
      "source": [
        "Podpięcie dysku Google"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vFVM7qlZiAa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XygAdPx6CquD",
        "colab_type": "text"
      },
      "source": [
        "Biblioteki"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJ2y2x_RCPrs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# path\n",
        "import os\n",
        "from os.path import isdir, join\n",
        "from pathlib import Path\n",
        "\n",
        "# Scientific Math \n",
        "import numpy as np\n",
        "from scipy.fftpack import fft\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import plotly.offline as py\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "# Deep learning\n",
        "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, LSTM\n",
        "from keras.layers import Activation, TimeDistributed, Embedding, CuDNNLSTM \n",
        "from keras.layers import Bidirectional, Permute, Reshape, Flatten, Lambda\n",
        "from keras.layers import Conv2D, Dot, Softmax\n",
        "from keras import Input, layers, utils, optimizers, losses\n",
        "from keras import backend as K\n",
        "from keras.models import Model, Sequential\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.backend import squeeze\n",
        "\n",
        "from kapre.time_frequency import Melspectrogram\n",
        "from kapre.utils import Normalization2D\n",
        "\n",
        "import random\n",
        "import copy\n",
        "import librosa"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqzy92VECsSD",
        "colab_type": "text"
      },
      "source": [
        "Ładowanie danych i preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ld2bq3BCR-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_audio_path = 'data/train/audio/'\n",
        "\n",
        "dirs = [f for f in os.listdir(train_audio_path) if isdir(join(train_audio_path, f))]\n",
        "dirs.sort()\n",
        "print('Number of labels: ' + str(len(dirs[1:])))\n",
        "print(dirs)\n",
        "\n",
        "all_wav = []\n",
        "unknown_wav = []\n",
        "label_all = []\n",
        "label_value = {}\n",
        "target_list = ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go']\n",
        "unknown_list = [d for d in dirs if d not in target_list and d != '_background_noise_' ]\n",
        "print('target_list : ',end='')\n",
        "print(target_list)\n",
        "print('unknowns_list : ', end='')\n",
        "print(unknown_list)\n",
        "print('silence : _background_noise_')\n",
        "i = 0\n",
        "background = [f for f in os.listdir(join(train_audio_path, '_background_noise_')) if f.endswith('.wav')]\n",
        "background_noise = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCvgt37u0HVZ",
        "colab_type": "text"
      },
      "source": [
        "Konwersja z użyciem librosa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0PVV8mAq0-o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for wav in background : \n",
        "    samples, sample_rate = librosa.load(join(join(train_audio_path,'_background_noise_'),wav))\n",
        "    samples = librosa.resample(samples, sample_rate, 8000)\n",
        "    background_noise.append(samples) \n",
        "\n",
        "for direct in dirs[1:]:\n",
        "    waves = [f for f in os.listdir(join(train_audio_path, direct)) if f.endswith('.wav')]\n",
        "    label_value[direct] = i\n",
        "    i = i + 1\n",
        "    print(str(i)+\":\" +str(direct) + \" \")\n",
        "    \n",
        "    for wav in waves:\n",
        "        samples, sample_rate = librosa.load(join(join(train_audio_path,direct),wav), sr = 16000)\n",
        "        samples = librosa.resample(samples, sample_rate, 8000)\n",
        "        \n",
        "        if len(samples) != 8000: \n",
        "            continue\n",
        "            \n",
        "        if direct in unknown_list:\n",
        "            unknown_wav.append(samples)\n",
        "        else:\n",
        "            label_all.append(direct)\n",
        "            all_wav.append([samples, direct])\n",
        "           \n",
        "wav_all = np.reshape(np.delete(all_wav,1,1),(len(all_wav)))\n",
        "label_all = [i for i in np.delete(all_wav,0,1).tolist()]\n",
        "\n",
        "# Random pick start point\n",
        "def get_one_noise(noise_num = 0):\n",
        "    selected_noise = background_noise[noise_num]\n",
        "    start_idx = random.randint(0, len(selected_noise)- 1 - 8000)\n",
        "    return selected_noise[start_idx:(start_idx + 8000)]\n",
        "  \n",
        "max_ratio = 0.1\n",
        "noised_wav = []\n",
        "augment = 1\n",
        "delete_index = []\n",
        "for i in range(augment):\n",
        "    new_wav = []\n",
        "    noise = get_one_noise(i)\n",
        "    for i, s in enumerate(wav_all):\n",
        "        if len(s) != 8000:\n",
        "            delete_index.append(i)\n",
        "            continue\n",
        "        s = s + (max_ratio * noise)\n",
        "        noised_wav.append(s)\n",
        "np.delete(wav_all, delete_index)\n",
        "np.delete(label_all, delete_index)\n",
        "\n",
        "\n",
        "wav_vals = np.array([x for x in wav_all])\n",
        "label_vals = [x for x in label_all]\n",
        "wav_vals.shape\n",
        "\n",
        "labels = copy.deepcopy(label_vals)\n",
        "for _ in range(augment):\n",
        "    label_vals = np.concatenate((label_vals, labels), axis = 0)\n",
        "label_vals = label_vals.reshape(-1,1)\n",
        "\n",
        "# knowns audio random sampling\n",
        "unknown = unknown_wav\n",
        "np.random.shuffle(unknown_wav)\n",
        "unknown = np.array(unknown)\n",
        "unknown = unknown[:2000*(augment+1)]\n",
        "unknown_label = np.array(['unknown' for _ in range(2000*(augment+1))])\n",
        "unknown_label = unknown_label.reshape(2000*(augment+1),1)\n",
        "\n",
        "delete_index = []\n",
        "for i,w in enumerate(unknown):\n",
        "    if len(w) != 8000:\n",
        "        delete_index.append(i)\n",
        "unknown = np.delete(unknown, delete_index, axis=0)\n",
        "\n",
        "# silence audio\n",
        "silence_wav = []\n",
        "num_wav = (2000*(augment+1))//len(background_noise)\n",
        "for i, _ in enumerate(background_noise):\n",
        "    for _ in range((2000*(augment+1))//len(background_noise)):\n",
        "        silence_wav.append(get_one_noise(i))\n",
        "silence_wav = np.array(silence_wav)\n",
        "silence_label = np.array(['silence' for _ in range(num_wav*len(background_noise))])\n",
        "silence_label = silence_label.reshape(-1,1)\n",
        "silence_wav.shape\n",
        "\n",
        "wav_vals    = np.reshape(wav_vals,    (-1, 8000))\n",
        "noised_wav  = np.reshape(noised_wav,  (-1, 8000))\n",
        "unknown       = np.reshape(unknown,   (-1, 8000))\n",
        "silence_wav = np.reshape(silence_wav, (-1, 8000))\n",
        "\n",
        "print(wav_vals.shape)\n",
        "print(noised_wav.shape)\n",
        "print(unknown.shape)\n",
        "print(silence_wav.shape)\n",
        "\n",
        "print(label_vals.shape)\n",
        "print(unknown_label.shape)\n",
        "print(silence_label.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IdbYuOF0Ref",
        "colab_type": "text"
      },
      "source": [
        "Zapis danych do plików numpy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SciB22dLQIsj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_path = 'gdrive/My Drive/DL2020/Projekt3/numpy_data'\n",
        "\n",
        "with open(join(save_path, 'wav_vals.npy'), 'wb+') as f:\n",
        "    np.save(f, wav_vals)\n",
        "with open(join(save_path, 'noised_wav.npy'), 'wb+') as f:\n",
        "    np.save(f, noised_wav)\n",
        "with open(join(save_path, 'unknown.npy'), 'wb+') as f:\n",
        "    np.save(f, unknown)\n",
        "with open(join(save_path, 'silence_wav.npy'), 'wb+') as f:\n",
        "    np.save(f, silence_wav)\n",
        "with open(join(save_path, 'label_vals.npy'), 'wb+') as f:\n",
        "    np.save(f, label_vals)\n",
        "with open(join(save_path, 'unknown_label.npy'), 'wb+') as f:\n",
        "    np.save(f, unknown_label)\n",
        "with open(join(save_path, 'silence_label.npy'), 'wb+') as f:\n",
        "    np.save(f, silence_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyVylIIL0Zd9",
        "colab_type": "text"
      },
      "source": [
        "Ładowanie danych z plików"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wA6oQ_SaO_-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "load_path = 'gdrive/My Drive/DL2020/Projekt3/numpy_data'\n",
        "\n",
        "wav_vals = np.load(join(load_path, 'wav_vals.npy'))\n",
        "noised_wav = np.load(join(load_path, 'noised_wav.npy'))\n",
        "unknown = np.load(join(load_path, 'unknown.npy'))\n",
        "silence_wav = np.load(join(load_path, 'silence_wav.npy'))\n",
        "label_vals = np.load(join(load_path, 'label_vals.npy'))\n",
        "unknown_label = np.load(join(load_path, 'unknown_label.npy'))\n",
        "silence_label = np.load(join(load_path, 'silence_label.npy'))\n",
        "\n",
        "print(wav_vals.shape)\n",
        "print(noised_wav.shape)\n",
        "print(unknown.shape)\n",
        "print(silence_wav.shape)\n",
        "\n",
        "print(label_vals.shape)\n",
        "print(unknown_label.shape)\n",
        "print(silence_label.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4q7RmGt0ffo",
        "colab_type": "text"
      },
      "source": [
        "Podział na zbiory treningowy i testowy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UA9SYD7LO5Xv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wav_vals = np.concatenate((wav_vals, noised_wav), axis = 0)\n",
        "wav_vals = np.concatenate((wav_vals, unknown), axis = 0)\n",
        "wav_vals = np.concatenate((wav_vals, silence_wav), axis = 0)\n",
        "\n",
        "label_vals = np.concatenate((label_vals, unknown_label), axis = 0)\n",
        "label_vals = np.concatenate((label_vals, silence_label), axis = 0)\n",
        "\n",
        "print(len(wav_vals))\n",
        "print(len(label_vals))\n",
        "\n",
        "train_wav, test_wav, train_label, test_label = train_test_split(wav_vals, label_vals, \n",
        "                                                                    test_size=0.2,\n",
        "                                                                    random_state = 1993,\n",
        "                                                                   shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwFOxFHOCwUR",
        "colab_type": "text"
      },
      "source": [
        "Parametry uczenia i sieci"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "al8G6gbBCx9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 0.001\n",
        "batch_size = 512\n",
        "drop_out_rate = 0.5\n",
        "input_shape = 8000\n",
        "units = 10\n",
        "recur_layers = 10\n",
        "embed_dim = 32\n",
        "lstm_out = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwMnz8svDCgr",
        "colab_type": "text"
      },
      "source": [
        "Parametry do zapisu modelu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFKdUfYtDER1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_dir = 'gdrive/My Drive/DL2020/Projekt3/saved_models/'\n",
        "model_name = 'v1_trained_model.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8W-FqB2C7lH",
        "colab_type": "text"
      },
      "source": [
        "Preprocessingu cd."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asNVOLBwC-JE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_value = target_list\n",
        "label_value.append('unknown')\n",
        "label_value.append('silence')\n",
        "\n",
        "new_label_value = dict()\n",
        "for i, l in enumerate(label_value):\n",
        "    new_label_value[l] = i\n",
        "label_value = new_label_value\n",
        "\n",
        "# Make Label data 'string' -> 'class num'\n",
        "temp = []\n",
        "for v in train_label:\n",
        "    temp.append(label_value[v[0]])\n",
        "train_label = np.array(temp)\n",
        "\n",
        "temp = []\n",
        "for v in test_label:\n",
        "    temp.append(label_value[v[0]])\n",
        "test_label = np.array(temp)\n",
        "\n",
        "# Make Label data 'class num' -> 'One hot vector'\n",
        "train_label = utils.to_categorical(train_label, len(label_value))\n",
        "test_label = utils.to_categorical(test_label, len(label_value))\n",
        "\n",
        "print('Train_Wav Demension : ' + str(np.shape(train_wav)))\n",
        "\n",
        "print('Train_Label Demension : ' + str(np.shape(train_label)))\n",
        "\n",
        "print('Test_Wav Demension : ' + str(np.shape(test_wav)))\n",
        "\n",
        "print('Test_Label Demension : ' + str(np.shape(test_label)))\n",
        "\n",
        "print('Number Of Labels : ' + str(len(label_value)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAfG-Ud_DJ7U",
        "colab_type": "text"
      },
      "source": [
        "Przykładowy model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xw98tMzCxyH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip uninstall tensorflow\n",
        "!pip install tensorflow==1.13.2\n",
        "!pip install tensorflow-gpu==1.13.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tINnoOoUDNUF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = len(label_value)\n",
        "\n",
        "def create_model():\n",
        "    x_in = Input((8000,))\n",
        "\n",
        "    x = Reshape((1, -1))(x_in)\n",
        "\n",
        "    x = Melspectrogram(n_dft=1024, n_hop=128, input_shape=(1, 8000),\n",
        "                       padding='same', sr=8000, n_mels=80,\n",
        "                       fmin=20.0, fmax=8000 / 2, power_melgram=1.0,\n",
        "                       return_decibel_melgram=True, trainable_fb=False,\n",
        "                       trainable_kernel=False,\n",
        "                       name='mel_stft')(x)\n",
        "    x = Normalization2D(int_axis=0)(x)\n",
        "    x = Permute((2, 1, 3))(x)\n",
        "\n",
        "    x = Conv2D(10, (5, 1), activation='relu', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(1, (5, 1), activation='relu', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    # x = Reshape((125, 80)) (x)\n",
        "    x = Lambda(lambda q: squeeze(q, -1), name='squeeze_last_dim')(x)  # keras.backend.squeeze(x, axis)\n",
        "\n",
        "    x = Bidirectional(CuDNNLSTM(32, return_sequences=True))(x)  # [b_s, seq_len, vec_dim]\n",
        "    x = Bidirectional(CuDNNLSTM(32, return_sequences=True))(x)  # [b_s, seq_len, vec_dim]\n",
        "\n",
        "    x_first = Lambda(lambda q: q[:, 32])(x)  # [b_s, vec_dim]\n",
        "    query = Dense(64)(x_first)\n",
        "\n",
        "    # dot product attention\n",
        "    attention_scores = Dot(axes=[1, 2])([query, x])\n",
        "    attention_scores = Softmax(name='attSoftmax')(attention_scores)  # [b_s, seq_len]\n",
        "\n",
        "    # rescale sequence\n",
        "    attention_vector = Dot(axes=[1, 1])([attention_scores, x])  # [b_s, vec_dim]\n",
        "\n",
        "    x = Dense(32, activation='relu')(attention_vector)\n",
        "    x = Dense(16)(x)\n",
        "\n",
        "    output = Dense(num_classes, activation='softmax', name='output')(x)\n",
        "\n",
        "    return Model(inputs=x_in, outputs=output)\n",
        "\n",
        "model = create_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-pp28jODSCv",
        "colab_type": "text"
      },
      "source": [
        "Ustawienie checkpointu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJe5Oqy0DVNN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# checkpoint\n",
        "filepath=\"gdrive/My Drive/DL2020/Projekt3/saved_models/weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCPXReM2DdVg",
        "colab_type": "text"
      },
      "source": [
        "Trenowanie modelu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4y17Ne5Gxn4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "sess = tf.Session(config=config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b6I0bMQDbL3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='sgd', loss='mean_squared_error')\n",
        "history = model.fit(train_wav, train_label, validation_data=[test_wav, test_label],\n",
        "          batch_size=batch_size, \n",
        "          epochs=100,\n",
        "          callbacks=callbacks_list,\n",
        "          verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmfxYChxDhYm",
        "colab_type": "text"
      },
      "source": [
        "Zapis modelu do pliku"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsqEU3u6NrXg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "model.save(model_path)\n",
        "print('Saved trained model at %s ' % model_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAGX3G6JDoNr",
        "colab_type": "text"
      },
      "source": [
        "Wypakowanie danych testowych"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZTROyzO8zpS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!7z x test.7z -o/content/data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2UH84QeEvMh",
        "colab_type": "text"
      },
      "source": [
        "Preprocessing na danych testowych"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTw53dY1ExO1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_audio_path = 'data/test/audio/'\n",
        "\n",
        "label_value = {}\n",
        "target_list = ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go']\n",
        "\n",
        "label_value = target_list\n",
        "label_value.append('unknown')\n",
        "label_value.append('silence')\n",
        "\n",
        "new_label_value = dict()\n",
        "for i, l in enumerate(label_value):\n",
        "    new_label_value[l] = i\n",
        "label_value = new_label_value\n",
        "\n",
        "all_wav = []\n",
        "\n",
        "waves = [f for f in os.listdir(test_audio_path) if f.endswith('.wav')]\n",
        "for wav in waves:\n",
        "  samples, sample_rate = librosa.load(join(test_audio_path, wav), sr = 16000)\n",
        "  samples = librosa.resample(samples, sample_rate, 8000)\n",
        "  if len(samples) != 8000 : \n",
        "    continue\n",
        "  all_wav.append([samples, wav])\n",
        "          \n",
        "wav_all = np.reshape(np.delete(all_wav,1,1),(len(all_wav)))\n",
        "\n",
        "test_data = np.array([x for x in wav_all])\n",
        "\n",
        "test_data = test_data.reshape(-1,8000)\n",
        "\n",
        "print(len(test_data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jye43MIRD--M",
        "colab_type": "text"
      },
      "source": [
        "Załadowanie modelu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wf9h-a84EB_u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_path = os.path.join(save_dir, model_name)\n",
        "model.load_weights(model_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sE0GlDGjEDpe",
        "colab_type": "text"
      },
      "source": [
        "Predykcja na zbiorze testowym"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kO4Z-oNhEC9g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_prob = model.predict(test_data) \n",
        "y_classes = y_prob.argmax(axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UW5kzmAIEPoN",
        "colab_type": "text"
      },
      "source": [
        "Zapis wyników na dysk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3l-RjSgRQHF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "it = 0\n",
        "with open('gdrive/My Drive/DL2020/Projekt3/results' + str(xStart) + '.csv', mode='w') as output_file:\n",
        "  output_writer = csv.writer(output_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "  for y in y_classes:\n",
        "    output_writer.writerow([all_fnames[it], target_list[y]])\n",
        "    it = it + 1"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}