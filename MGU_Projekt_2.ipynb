{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MGU_Projekt_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gvnbleid/2020-GUM/blob/master/MGU_Projekt_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9Hp_79xzNHL",
        "colab_type": "text"
      },
      "source": [
        "# Integracja z Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cic3sCC_zWw-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "BASE_DIR = '/content/gdrive/My Drive/DL2020/Projekt2/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGdF3mbTx5wX",
        "colab_type": "text"
      },
      "source": [
        "# Sieć konwolucyjna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbzarbsUzYmX",
        "colab_type": "text"
      },
      "source": [
        "## Konfiguracja wstępna"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCe_msV2M8CU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqrpJX4iNbNb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "import time\n",
        "import copy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lATCtCUUBO1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cuda not available\")\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MKet71A1ySyb"
      },
      "source": [
        "### Definicje klas i metod"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxVjlRlJSKMn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AddGaussianNoise(object):\n",
        "    def __init__(self, mean=0., std=1.):\n",
        "        self.std = std\n",
        "        self.mean = mean\n",
        "        \n",
        "    def __call__(self, tensor):\n",
        "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
        "    \n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r0OV8hAEyTuI",
        "colab": {}
      },
      "source": [
        "def update_classify_table(classify_table, predictions, labels):\n",
        "        for lab, pred in zip(labels, predictions):\n",
        "            classify_table[lab, pred] += 1\n",
        "\n",
        "def train_step(last_epoch):\n",
        "    running_loss = 0.0\n",
        "    for i, (img, label) in enumerate(trainloader):\n",
        "        img = img.to(device)\n",
        "        label = label.to(device)\n",
        "        net.train()\n",
        "        optimizer.zero_grad()\n",
        "        prediction = net(img)\n",
        "        loss = None\n",
        "        if config == \"Zmodyfikowany LeNet-5\" or config == \"Wlasna konfiguracja 1\":\n",
        "            print(\"dupa\")\n",
        "            loss = criterion(prediction[0], label)\n",
        "        else:\n",
        "            print(\"gowno\")\n",
        "            loss = criterion(prediction, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "    return running_loss\n",
        "    \n",
        "\n",
        "def print_accuracy():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        net.eval()\n",
        "        classify_table = np.zeros((10,10))\n",
        "        for i, (img, label) in enumerate(testloader):\n",
        "            img = img.to(device)\n",
        "            label = label.to(device)\n",
        "            prediction = net(img)\n",
        "            if config == \"Zmodyfikowany LeNet-5\" or config == \"Wlasna konfiguracja 1\":\n",
        "                loss += criterion(prediction[0], label)\n",
        "                _ , prediction = torch.max(prediction[0].data, 1)\n",
        "            else:\n",
        "                loss += criterion(prediction, label)\n",
        "                _ , prediction = torch.max(prediction.data, 1)\n",
        "            update_classify_table(classify_table, prediction, label.data)\n",
        "            correct += torch.sum(prediction == label.data)\n",
        "\n",
        "    accuracy = correct.cpu().numpy() / 10000\n",
        "    print('Accuracy of the network on the 10000 test images: %.2f %%' % (\n",
        "        100 * accuracy))   \n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Kd9WjZWjh62D"
      },
      "source": [
        "## Konfiguracja sieci"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTvGIHBbabZS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Wybór konfiguracji { run: \"auto\" }\n",
        "\n",
        "config = \"Pretrained VGG16\" #@param [\"Adventures in Machine Learning\", \"PyTorch tutorial\", \"Zmodyfikowany LeNet-5\", \"Wlasna konfiguracja 1\", \"Pretrained VGG16\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nlYrau21h62E",
        "colab": {}
      },
      "source": [
        "last_epoch = 0\n",
        "last_loss = None\n",
        "\n",
        "class Net(nn.Module):\n",
        "    if config == \"PyTorch tutorial\":\n",
        "        def __init__(self):\n",
        "            super(Net, self).__init__()\n",
        "            self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "            self.pool = nn.MaxPool2d(2, 2)\n",
        "            self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "            self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "            self.fc2 = nn.Linear(120, 84)\n",
        "            self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = self.pool(F.relu(self.conv1(x)))\n",
        "            x = self.pool(F.relu(self.conv2(x)))\n",
        "            x = x.view(-1, 16 * 5 * 5)\n",
        "            x = F.relu(self.fc1(x))\n",
        "            x = F.relu(self.fc2(x))\n",
        "            x = self.fc3(x)\n",
        "            return x\n",
        "\n",
        "    elif config == \"Adventures in Machine Learning\":\n",
        "        def __init__(self):\n",
        "            super(Net, self).__init__()\n",
        "            self.conv1 = nn.Conv2d(3, 32, 5)\n",
        "            self.pool = nn.MaxPool2d(2, 2)\n",
        "            self.conv2 = nn.Conv2d(32, 64, 5)\n",
        "            self.fc1 = nn.Linear(64 * 5 * 5, 1000)\n",
        "            self.fc2 = nn.Linear(1000, 10)\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = self.pool(F.relu(self.conv1(x)))\n",
        "            x = self.pool(F.relu(self.conv2(x)))\n",
        "            x = x.view(-1, 64 * 5 * 5)\n",
        "            x = F.relu(self.fc1(x))\n",
        "            x = F.softmax(self.fc2(x), dim=0)\n",
        "            return x\n",
        "\n",
        "    elif config == \"Zmodyfikowany LeNet-5\":\n",
        "        def __init__(self):\n",
        "            super(Net, self).__init__()\n",
        "\n",
        "            self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 8, stride = 1, kernel_size = 3, padding = 1)\n",
        "            self.relu1 = nn.ReLU()\n",
        "            self.conv2 = nn.Conv2d(in_channels = 8, out_channels = 16, stride = 1, kernel_size = 3, padding = 1)\n",
        "            self.relu2 = nn.ReLU()\n",
        "            self.maxpool1 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "            self.conv3 = nn.Conv2d(in_channels = 16, out_channels = 32, stride = 1, kernel_size = 3, padding = 0)\n",
        "            self.relu3 = nn.ReLU()\n",
        "            self.maxpool2 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "            self.linear1 = nn.Linear(7 * 7 * 32, 300)\n",
        "            self.relu4 = nn.ReLU()\n",
        "            self.drop1 = nn.Dropout(p = 0.5)\n",
        "            self.linear2 = nn.Linear(300, 10)\n",
        "\n",
        "            self.net = nn.Sequential(self.conv1, self.relu1, self.conv2, self.relu2,\n",
        "                                 self.maxpool1, self.conv3, self.relu3, self.maxpool2)\n",
        "                                             \n",
        "        def forward(self, x):\n",
        "            x = self.net(x)\n",
        "            x = x.view(-1, x.shape[0] , 7 * 7 * 32)\n",
        "            x = self.linear1(x)\n",
        "            x = self.relu4(x)\n",
        "            x = self.drop1(x)\n",
        "            x = self.linear2(x)\n",
        "            return x\n",
        "\n",
        "    elif config == \"Wlasna konfiguracja 1\":\n",
        "        def __init__(self):\n",
        "            super(Net, self).__init__()\n",
        "\n",
        "            self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 16, stride = 1, kernel_size = 3, padding = 1)\n",
        "            self.batchnorm1 = nn.BatchNorm2d(num_features = 16)\n",
        "            self.relu1 = nn.ReLU()\n",
        "            self.conv2 = nn.Conv2d(in_channels = 16, out_channels = 32, stride = 1, kernel_size = 3, padding = 1)\n",
        "            self.batchnorm2 = nn.BatchNorm2d(num_features = 32)\n",
        "            self.relu2 = nn.ReLU()\n",
        "            self.maxpool2 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "            self.conv3 = nn.Conv2d(in_channels = 32, out_channels = 64, stride = 1, kernel_size = 3, padding = 0)\n",
        "            self.batchnorm3 = nn.BatchNorm2d(num_features = 64)\n",
        "            self.relu3 = nn.ReLU()\n",
        "            self.maxpool3 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "            self.linear1 = nn.Linear(7 * 7 * 64, 300)\n",
        "            self.relu4 = nn.ReLU()\n",
        "            self.drop1 = nn.Dropout(p = 0.5)\n",
        "            self.linear2 = nn.Linear(300, 10)\n",
        "            self.net = nn.Sequential(self.conv1, self.batchnorm1, self.relu1, self.conv2, self.batchnorm2, self.relu2,\n",
        "                                 self.maxpool2, self.conv3, self.batchnorm3, self.relu3, self.maxpool3)\n",
        "                                             \n",
        "        def forward(self, x):\n",
        "            x = self.net(x)\n",
        "            x = x.view(-1, x.shape[0] , 7 * 7 * 64)\n",
        "            x = self.linear1(x)\n",
        "            x = self.relu4(x)\n",
        "            x = self.drop1(x)\n",
        "            x = self.linear2(x)\n",
        "            return x\n",
        "\n",
        "net = None\n",
        "input_size = 32\n",
        "\n",
        "if config == \"Pretrained VGG16\":\n",
        "    def set_parameter_requires_grad(model):\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    net = models.vgg16_bn(pretrained=True)\n",
        "    set_parameter_requires_grad(net)\n",
        "    num_ftrs = net.classifier[6].in_features\n",
        "    net.classifier[6] = nn.Linear(num_ftrs, 10)\n",
        "    net = net.to(device)\n",
        "    input_size = 224\n",
        "else:\n",
        "    net = Net().to(device)\n",
        "\n",
        "net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vmlgb9OGTqW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchsummary import summary\n",
        "summary(net, input_size=(3, input_size, input_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5dtraYJ9wTC",
        "colab_type": "text"
      },
      "source": [
        "### Wczytanie stanu sieci (opcjonalne)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEhQaYFv96A8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "load_state = True #@param {type: \"boolean\"}\n",
        "path = \"wlasna_best_20.04.19_15:40:35.pt\" #@param {type: \"string\"}\n",
        "\n",
        "if load_state:\n",
        "    checkpoint = torch.load(BASE_DIR + path)\n",
        "    net.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    criterion.load_state_dict(checkpoint['criterion_state_dict'])\n",
        "    last_epoch = checkpoint['epoch']\n",
        "    last_loss = checkpoint['loss']\n",
        "    loss_array = checkpoint['loss_array']\n",
        "    acc_array = checkpoint['acc_array']\n",
        "    net.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TspiX6PyB9N",
        "colab_type": "text"
      },
      "source": [
        "## Ustawienia augmentacji danych"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "cellView": "both",
        "id": "Fi58HhASh62i",
        "colab": {}
      },
      "source": [
        "#@title Metody augmentacji { run: \"auto\" }\n",
        "translation_checkbox = False #@param {type:\"boolean\"}\n",
        "flip_checkbox = True #@param {type:\"boolean\"}\n",
        "rotation_checkbox = False #@param {type:\"boolean\"}\n",
        "noise_checkbox = False #@param {type:\"boolean\"}\n",
        "color_checkbox = True #@param {type:\"boolean\"}\n",
        "crop_checkbox = True #@param {type:\"boolean\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xQe85qmoh62o",
        "colab": {}
      },
      "source": [
        "transforms_array_train = []\n",
        "\n",
        "transforms_array_train.append(transforms.Resize(size=(input_size, input_size)))\n",
        "\n",
        "if crop_checkbox:\n",
        "    transforms_array_train.append(transforms.RandomCrop(padding=None, size=(input_size, input_size)))\n",
        "if translation_checkbox:\n",
        "    transforms_array_train.append(transforms.RandomAffine(0, (0.2, 0.2)))\n",
        "if flip_checkbox:\n",
        "    transforms_array_train.append(transforms.RandomHorizontalFlip(p=0.5))\n",
        "if rotation_checkbox:\n",
        "    transforms_array_train.append(transforms.RandomRotation(degrees=(-15,15), resample=False, expand=False))\n",
        "if color_checkbox:\n",
        "    transforms_array_train.append(transforms.ColorJitter(brightness=[0.8,1.2], contrast=[0.8,1.2], saturation=[0.8,1.2]))\n",
        "if noise_checkbox:\n",
        "    transforms_array_train.append(AddGaussianNoise(0., 0.2))\n",
        "\n",
        "transforms_array_train.append(transforms.ToTensor())\n",
        "transforms_array_train.append(transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                            std=[0.229, 0.224, 0.225]))\n",
        "transforms_array_test = []\n",
        "\n",
        "transforms_array_test.append(transforms.Resize(size=(input_size, input_size)))\n",
        "transforms_array_test.append(transforms.ToTensor())\n",
        "transforms_array_test.append(transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                             std=[0.229, 0.224, 0.225]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgDB0MJEyLUv",
        "colab_type": "text"
      },
      "source": [
        "## Wczytanie danych"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23wbllWBNfEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform_train = transforms.Compose(transforms_array_train)\n",
        "transform_test = transforms.Compose(transforms_array_test)\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SeGEuKv9h620",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(10)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoUP71A0SV81",
        "colab_type": "text"
      },
      "source": [
        "## Uczenie sieci - funkcja"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OTwvrYBd2Cf",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "nb_epoch = 10 #@param {type: \"integer\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glx9mQvCSd6l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_net(net, dataloaders, criterion, optimizer, nb_epoch, last_epoch):\n",
        "    since = time.time()\n",
        "\n",
        "    test_acc_array = []\n",
        "    train_acc_array = []\n",
        "    loss_array = []\n",
        "    best_net = copy.deepcopy(net.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(nb_epoch):  # loop over the dataset multiple times\n",
        "        last_epoch = last_epoch + 1\n",
        "\n",
        "        for phase in ['train', 'test']:\n",
        "            if phase == 'train':\n",
        "                net.train()\n",
        "                dataloader = dataloaders[0]\n",
        "            else:\n",
        "                net.eval()\n",
        "                dataloader = dataloaders[1]\n",
        "        \n",
        "            running_loss = 0.0\n",
        "            running_correct = 0\n",
        "\n",
        "            for inputs, labels in dataloader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                \n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # forward + backward + optimize\n",
        "                    outputs = net(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, prediction = torch.max(outputs, 1)\n",
        "                    \n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # print statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_correct += torch.sum(prediction == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloader.dataset)\n",
        "            epoch_acc = running_correct.double() / len(dataloader.dataset)\n",
        "\n",
        "            print('Epoch %s/%s - %s Loss: %.3f Acc: %.3f' %\n",
        "                (epoch + 1, nb_epoch, phase, epoch_loss, epoch_acc))\n",
        "            \n",
        "            if phase == 'test' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_net = copy.deepcopy(net.state_dict())\n",
        "            if phase == 'test':\n",
        "                test_acc_array.append(epoch_acc)\n",
        "            else:\n",
        "                train_acc_array.append(epoch_acc)\n",
        "            loss_array.append(epoch_loss)\n",
        "    \n",
        "    training_time = time.time() - since\n",
        "    print('Finished Training in %.0fm %.0fs' % (training_time // 60, training_time % 60))\n",
        "    print('Best test Accuracy: %.3f' % (best_acc))\n",
        "\n",
        "    net.load_state_dict(best_net)\n",
        "    return net, test_acc_array, train_acc_array, loss_array\n",
        "\n",
        "net, test_acc_array, train_acc_array, loss_array = train_net(net, [trainloader, testloader], criterion, optimizer, nb_epoch, last_epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1Zt3tB75fcR",
        "colab_type": "text"
      },
      "source": [
        "## Zapis stanu modelu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMj0iZ3oacsW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from datetime import datetime\n",
        "\n",
        "def append_timestamp(path):\n",
        "    now = datetime.now()\n",
        "    current_time = now.strftime(\"%y.%m.%d_%H:%M:%S\")\n",
        "    return path.replace(\".\", f\"_{current_time}.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3IHZ3gd5joY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_model():\n",
        "    save_state = True #@param {type: \"boolean\"}\n",
        "    path = \"wlasna_best.pt\" #@param {type: \"string\"}\n",
        "    use_timestamp = True #@param {type: \"boolean\"}\n",
        "\n",
        "    if save_state:\n",
        "        if use_timestamp:\n",
        "            path = append_timestamp(path)\n",
        "        torch.save({\n",
        "                    'epoch': last_epoch,\n",
        "                    'model_state_dict': net.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    'criterion_state_dict': criterion.state_dict(),\n",
        "                    'loss': last_loss,\n",
        "                    'loss_array': loss_array,\n",
        "                    'acc_array': acc_array\n",
        "                    }, BASE_DIR + path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lr82fiblseX7",
        "colab_type": "text"
      },
      "source": [
        "## Uczenie sieci"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNk0QD6ytHSR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer_type = \"SGD\" #@param [\"SGD\", \"Adam\"]\n",
        "lr = 0.001 #@param {type: \"number\"}\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "params_to_update = []\n",
        "for param in net.parameters():\n",
        "    if param.requires_grad == True:\n",
        "        params_to_update.append(param)\n",
        "\n",
        "optimizer = None\n",
        "\n",
        "if optimizer_type == \"SGD\":\n",
        "    optimizer = optim.SGD(params_to_update, lr=lr, momentum=0.9)\n",
        "if optimizer_type == \"Adam\":\n",
        "    optimizer = optim.Adam(params_to_update, lr = 0.000002, weight_decay=0.002)\n",
        "\n",
        "def update_classify_table(classify_table, predictions, labels):\n",
        "        for lab, pred in zip(labels, predictions):\n",
        "            classify_table[lab, pred] += 1\n",
        "\n",
        "def train_step(last_epoch):\n",
        "    running_loss = 0.0\n",
        "    for i, (img, label) in enumerate(trainloader):\n",
        "        img = img.to(device)\n",
        "        label = label.to(device)\n",
        "        net.train()\n",
        "        optimizer.zero_grad()\n",
        "        prediction = net(img)\n",
        "        loss = None\n",
        "        if config == \"Zmodyfikowany LeNet-5\" or config == \"Wlasna konfiguracja 1\":\n",
        "            loss = criterion(prediction[0], label)\n",
        "        else:\n",
        "            loss = criterion(prediction, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if config == \"Zmodyfikowany LeNet-5\" or config == \"Wlasna konfiguracja 1\":\n",
        "            running_loss += loss.item()\n",
        "        else:\n",
        "            running_loss += loss.item() * img.size(0)\n",
        "    return running_loss\n",
        "    \n",
        "\n",
        "def print_accuracy():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        net.eval()\n",
        "        classify_table = np.zeros((10,10))\n",
        "        for i, (img, label) in enumerate(testloader):\n",
        "            img = img.to(device)\n",
        "            label = label.to(device)\n",
        "            prediction = net(img)\n",
        "            if config == \"Zmodyfikowany LeNet-5\" or config == \"Wlasna konfiguracja 1\":\n",
        "                loss += criterion(prediction[0], label)\n",
        "                _ , prediction = torch.max(prediction[0].data, 1)\n",
        "            else:\n",
        "                loss += criterion(prediction, label)\n",
        "                _ , prediction = torch.max(prediction.data, 1)\n",
        "            update_classify_table(classify_table, prediction, label.data)\n",
        "            correct += torch.sum(prediction == label.data)\n",
        "\n",
        "    accuracy = correct.cpu().numpy() / 10000\n",
        "    print('Accuracy of the network on the 10000 test images: %.2f %%' % (\n",
        "        100 * accuracy))   \n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YS0hPb22b6cw",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "nb_epoch =  3#@param {type: \"integer\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqjQfl713qAU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "counter = 0\n",
        "best_net = copy.deepcopy(net.state_dict())\n",
        "\n",
        "loss_array = []\n",
        "acc_array = []\n",
        "max_acc = 0\n",
        "\n",
        "for e in range(nb_epoch):\n",
        "    last_epoch = last_epoch + 1\n",
        "    running_loss = train_step(last_epoch)\n",
        "    if config == \"Zmodyfikowany LeNet-5\" or config == \"Wlasna konfiguracja 1\":\n",
        "        last_loss = running_loss / 500\n",
        "    else:\n",
        "        last_loss = running_loss / len(trainloader.dataset)\n",
        "    print('%d epoch, loss: %.4f' % (last_epoch, last_loss))\n",
        "    loss_array.append(last_loss)\n",
        "    curr_acc = print_accuracy()\n",
        "    acc_array.append(curr_acc)\n",
        "    if curr_acc > max_acc:\n",
        "        #save_model()\n",
        "        best_net = copy.deepcopy(net.state_dict())\n",
        "        max_acc = curr_acc\n",
        "        counter = 0\n",
        "    else:\n",
        "        counter = counter + 1\n",
        "        if counter > 2:\n",
        "            break\n",
        "\n",
        "net.load_state_dict(best_net)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVzNqlh92IL0",
        "colab_type": "text"
      },
      "source": [
        "## Wyniki"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zleCjE2NOFs5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "loss = 0.0\n",
        "with torch.no_grad():\n",
        "    net.eval()\n",
        "    classify_table = np.zeros((10,10))\n",
        "    for i, (img, label) in enumerate(testloader):\n",
        "        img = img.to(device)\n",
        "        label = label.to(device)\n",
        "        prediction = net(img)\n",
        "        if config == \"Zmodyfikowany LeNet-5\" or config == \"Wlasna konfiguracja 1\":\n",
        "            loss += criterion(prediction[0], label)\n",
        "            _ , prediction = torch.max(prediction[0].data, 1)\n",
        "        else:\n",
        "            loss += criterion(prediction, label)\n",
        "            _ , prediction = torch.max(prediction.data, 1)\n",
        "\n",
        "        update_classify_table(classify_table, prediction, label.data)\n",
        "        correct += torch.sum(prediction == label.data)\n",
        "\n",
        "accuracy = correct.cpu().numpy() / 10000\n",
        "print('Accuracy of the network on the 10000 test images: %.2f %%' % (\n",
        "    100 * accuracy)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaHcNGxUNxyu",
        "colab_type": "text"
      },
      "source": [
        "### Zapis wyników (opcjonalne)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XSrgc_SN3fr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_results_state = True #@param {type: \"boolean\"}\n",
        "use_timestamp = True #@param {type: \"boolean\"}\n",
        "path = \"pytorch_tutorial.json\" #@param {type: \"string\"}\n",
        "\n",
        "from datetime import datetime\n",
        "import json\n",
        "import codecs\n",
        "\n",
        "if save_results_state:\n",
        "    if use_timestamp:\n",
        "        path = append_timestamp(path)\n",
        "\n",
        "    json.dump(dict(accuracy=accuracy, classify_table=accuracy_per_class),\n",
        "              codecs.open(BASE_DIR + path, 'w', encoding='utf-8'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZ_bbCQBY4ML",
        "colab_type": "text"
      },
      "source": [
        "## Wykresy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OsDHNGBY5P2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = range(1, last_epoch + 1)\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "ax.set_xticks(np.arange(0, last_epoch + 1, 5))\n",
        "\n",
        "plt.scatter(epochs, loss_array)\n",
        "plt.title(\"Wykres funkcji straty dla zbioru treningowego\")\n",
        "plt.xlabel(\"Numer epoki\")\n",
        "plt.ylabel(\"Wartość funkcji straty\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_lxILwc9Npd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = range(1, last_epoch + 1)\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "ax.set_xticks(np.arange(0, last_epoch + 1))\n",
        "\n",
        "plt.scatter(epochs, acc_array)\n",
        "plt.title(\"Wykres dokładności dla zbioru walidacyjnego\")\n",
        "plt.xlabel(\"Numer epoki\")\n",
        "plt.ylabel(\"Dokładność\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9N0b7Eq3MN-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import copy\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "    \n",
        "def visualise_accuracy_by_class(classify_table):\n",
        "    results = [ classify_table[i,i] / np.sum(classify_table[i, :]) for i in range(10)]\n",
        "\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_axes([0,0,1,1])\n",
        "\n",
        "    plt.bar(classes, results, color = ['#7e57c2', '#ffc400'])\n",
        "    plt.title(\"Frakcja poprawnych klasyfikacji dla poszczególnych klas\")\n",
        "    plt.xlabel('Klasa')\n",
        "    plt.ylabel('Frakcja poprawnych klasyfikacji')\n",
        "    plt.xticks(classes)\n",
        "    plt.show()\n",
        "    \n",
        "def visualise_errors_by_class(classify_table):\n",
        "    p = list()\n",
        "    table = copy.deepcopy(classify_table)\n",
        "    table[np.argmax(table, 0), np.argmax(table, 1)] = 0\n",
        "    p.append(plt.bar(classes, table[:, 0]))\n",
        "    for i in range(1, 10):\n",
        "        p.append(plt.bar(classes, table[:, i], bottom = np.sum(table[:, 0:i], 1)))\n",
        "\n",
        "    plt.title(\"Błędy klasyfikacji\")\n",
        "    plt.xticks(classes)\n",
        "    plt.xlabel(\"Poprawna klasa\")\n",
        "    plt.ylabel(\"Liczba błędnych klasyfikacji\")\n",
        "    plt.legend(classes, title = \"Klasa zwracana przez sieć\", bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
        "    plt.show()\n",
        "\n",
        "def visualise_errors_for_class(classify_table, class_index):\n",
        "    p = list()\n",
        "    table = copy.deepcopy(classify_table)\n",
        "    table[np.argmax(table, 0), np.argmax(table, 1)] = 0\n",
        "\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_axes([0,0,1,1])\n",
        "\n",
        "    plt.bar(classes, table[:, class_index])\n",
        "    plt.xticks(classes)\n",
        "    plt.title(\"Liczba błędnych klasyfikacji dla klasy: {}\".format(classes[class_index]))\n",
        "    plt.xlabel(\"Klasa zwracana przez sieć\")\n",
        "    plt.ylabel(\"Liczba błędnych klasyfikacji\")\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLHPRXQg3Sxs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "visualise_accuracy_by_class(classify_table)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LChXagfO3vl9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "visualise_errors_by_class(classify_table)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4A8cUhQ5LxX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "visualise_errors_for_class(classify_table, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}