{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MGU_Projekt_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9Hp_79xzNHL",
        "colab_type": "text"
      },
      "source": [
        "# Integracja z Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cic3sCC_zWw-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "BASE_DIR = '/content/gdrive/My Drive/DL2020/Projekt2/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGdF3mbTx5wX",
        "colab_type": "text"
      },
      "source": [
        "# Sieć konwolucyjna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbzarbsUzYmX",
        "colab_type": "text"
      },
      "source": [
        "## Konfiguracja wstępna"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCe_msV2M8CU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqrpJX4iNbNb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import copy\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lATCtCUUBO1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxVjlRlJSKMn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AddGaussianNoise(object):\n",
        "    def __init__(self, mean=0., std=1.):\n",
        "        self.std = std\n",
        "        self.mean = mean\n",
        "        \n",
        "    def __call__(self, tensor):\n",
        "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
        "    \n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaYeENmgMuuw",
        "colab_type": "text"
      },
      "source": [
        "## Ustawienie ziarna"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQ8FU3HNMxP8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 0 #@param {type: \"integer\"}\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Kd9WjZWjh62D"
      },
      "source": [
        "## Konfiguracja sieci"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTvGIHBbabZS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Wybór konfiguracji { run: \"auto\" }\n",
        "\n",
        "config = \"GoogLeNet\" #@param [\"Zmodyfikowany LeNet-5\", \"Wlasna konfiguracja 1\", \"Pretrained VGG16\", \"GoogLeNet\"]\n",
        "transfer = \"Finetuning\" #@param [\"Finetuning\", \"Extract Features\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nlYrau21h62E",
        "colab": {}
      },
      "source": [
        "last_epoch = 0\n",
        "last_loss = None\n",
        "\n",
        "class Net(nn.Module):\n",
        "    if config == \"Zmodyfikowany LeNet-5\":\n",
        "        def __init__(self):\n",
        "            super(Net, self).__init__()\n",
        "\n",
        "            self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 8, stride = 1, kernel_size = 3, padding = 1)\n",
        "            self.relu1 = nn.ReLU()\n",
        "            self.conv2 = nn.Conv2d(in_channels = 8, out_channels = 16, stride = 1, kernel_size = 3, padding = 1)\n",
        "            self.relu2 = nn.ReLU()\n",
        "            self.maxpool1 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "            self.conv3 = nn.Conv2d(in_channels = 16, out_channels = 32, stride = 1, kernel_size = 3, padding = 0)\n",
        "            self.relu3 = nn.ReLU()\n",
        "            self.maxpool2 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "            self.linear1 = nn.Linear(7 * 7 * 32, 300)\n",
        "            self.relu4 = nn.ReLU()\n",
        "            self.drop1 = nn.Dropout(p = 0.5)\n",
        "            self.linear2 = nn.Linear(300, 10)\n",
        "\n",
        "            self.net = nn.Sequential(self.conv1, self.relu1, self.conv2, self.relu2,\n",
        "                                 self.maxpool1, self.conv3, self.relu3, self.maxpool2)\n",
        "                                             \n",
        "        def forward(self, x):\n",
        "            x = self.net(x)\n",
        "            x = x.view(-1, x.shape[0] , 7 * 7 * 32)\n",
        "            x = self.linear1(x)\n",
        "            x = self.relu4(x)\n",
        "            x = self.drop1(x)\n",
        "            x = self.linear2(x)\n",
        "            return x\n",
        "\n",
        "    elif config == \"Wlasna konfiguracja 1\":\n",
        "        def __init__(self):\n",
        "            super(Net, self).__init__()\n",
        "\n",
        "            self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 16, stride = 1, kernel_size = 3, padding = 1)\n",
        "            self.batchnorm1 = nn.BatchNorm2d(num_features = 16)\n",
        "            self.relu1 = nn.ReLU()\n",
        "            self.conv2 = nn.Conv2d(in_channels = 16, out_channels = 32, stride = 1, kernel_size = 3, padding = 1)\n",
        "            self.batchnorm2 = nn.BatchNorm2d(num_features = 32)\n",
        "            self.relu2 = nn.ReLU()\n",
        "            self.maxpool2 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "            self.conv3 = nn.Conv2d(in_channels = 32, out_channels = 64, stride = 1, kernel_size = 3, padding = 0)\n",
        "            self.batchnorm3 = nn.BatchNorm2d(num_features = 64)\n",
        "            self.relu3 = nn.ReLU()\n",
        "            self.maxpool3 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "            self.linear1 = nn.Linear(7 * 7 * 64, 300)\n",
        "            self.relu4 = nn.ReLU()\n",
        "            self.drop1 = nn.Dropout(p = 0.5)\n",
        "            self.linear2 = nn.Linear(300, 10)\n",
        "            self.net = nn.Sequential(self.conv1, self.batchnorm1, self.relu1, self.conv2, self.batchnorm2, self.relu2,\n",
        "                                 self.maxpool2, self.conv3, self.batchnorm3, self.relu3, self.maxpool3)\n",
        "                                             \n",
        "        def forward(self, x):\n",
        "            x = self.net(x)\n",
        "            x = x.view(-1, x.shape[0] , 7 * 7 * 64)\n",
        "            x = self.linear1(x)\n",
        "            x = self.relu4(x)\n",
        "            x = self.drop1(x)\n",
        "            x = self.linear2(x)\n",
        "            return x\n",
        "\n",
        "net = None\n",
        "input_size = 32\n",
        "\n",
        "def set_parameter_requires_grad(model):\n",
        "    if transfer == \"Extract Features\":\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "if config == \"Pretrained VGG16\":\n",
        "    net = models.vgg16_bn(pretrained=True)\n",
        "    set_parameter_requires_grad(net)\n",
        "    num_ftrs = net.classifier[6].in_features\n",
        "    net.classifier[6] = nn.Linear(num_ftrs, 10)\n",
        "    net = net.to(device)\n",
        "    input_size = 224\n",
        "elif config == \"GoogLeNet\":\n",
        "    net = models.googlenet(pretrained=True)\n",
        "    set_parameter_requires_grad(net)\n",
        "    num_ftrs = net.fc.in_features\n",
        "    net.fc = nn.Linear(num_ftrs, 10)\n",
        "    net = net.to(device)\n",
        "    input_size = 224\n",
        "else:\n",
        "    net = Net().to(device)\n",
        "\n",
        "loss_array = []\n",
        "acc_array = []\n",
        "max_acc = 0\n",
        "\n",
        "net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vmlgb9OGTqW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchsummary import summary\n",
        "summary(net, input_size=(3, input_size, input_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvhCyBaKtNX8",
        "colab_type": "text"
      },
      "source": [
        "### Kryterium i optymalizator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jv090D3ZtSeV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer_type = \"Adam\" #@param [\"SGD\", \"Adam\"]\n",
        "lr = 0.001 #@param {type: \"number\"}\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "params_to_update = []\n",
        "for param in net.parameters():\n",
        "    if param.requires_grad == True:\n",
        "        params_to_update.append(param)\n",
        "\n",
        "optimizer = None\n",
        "\n",
        "if optimizer_type == \"SGD\":\n",
        "    optimizer = optim.SGD(params_to_update, lr=lr, momentum=0.9)\n",
        "if optimizer_type == \"Adam\":\n",
        "    optimizer = optim.Adam(params_to_update, lr=lr, weight_decay=0.002)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5dtraYJ9wTC",
        "colab_type": "text"
      },
      "source": [
        "### Wczytanie stanu sieci (opcjonalne)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wTVDKz9p5Bm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_net_state(path):\n",
        "    if device == \"cuda:0\":\n",
        "        checkpoint = torch.load(path)\n",
        "    else:\n",
        "        checkpoint = torch.load(path, map_location=device)\n",
        "    net.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    criterion.load_state_dict(checkpoint['criterion_state_dict'])\n",
        "    last_epoch = checkpoint['epoch']\n",
        "    last_loss = checkpoint['loss']\n",
        "    loss_array = checkpoint['loss_array']\n",
        "    acc_array = checkpoint['acc_array']\n",
        "    if len(acc_array) > 0:\n",
        "        max_acc = np.max(acc_array)\n",
        "    else:\n",
        "        max_acc = 0\n",
        "    net.eval()\n",
        "    return net, optimizer, criterion, last_epoch, loss_array, acc_array, max_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEhQaYFv96A8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "load_state = True #@param {type: \"boolean\"}\n",
        "path = \"wlasna_best_acc_8333_0.pt\" #@param {type: \"string\"}\n",
        "\n",
        "if load_state:\n",
        "    net, optimizer, criterion, last_epoch, loss_array, acc_array, max_acc = load_net_state(BASE_DIR + path)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TspiX6PyB9N",
        "colab_type": "text"
      },
      "source": [
        "## Ustawienia augmentacji danych"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "cellView": "both",
        "id": "Fi58HhASh62i",
        "colab": {}
      },
      "source": [
        "#@title Metody augmentacji { run: \"auto\" }\n",
        "translation_checkbox = False #@param {type:\"boolean\"}\n",
        "flip_checkbox = True #@param {type:\"boolean\"}\n",
        "rotation_checkbox = False #@param {type:\"boolean\"}\n",
        "noise_checkbox = False #@param {type:\"boolean\"}\n",
        "color_checkbox = True #@param {type:\"boolean\"}\n",
        "crop_checkbox = True #@param {type:\"boolean\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xQe85qmoh62o",
        "colab": {}
      },
      "source": [
        "transforms_array_train = []\n",
        "\n",
        "if config == \"Pretrained VGG16\" or config == \"GoogLeNet\":\n",
        "    transforms_array_train.append(transforms.Resize(size=(input_size, input_size)))\n",
        "\n",
        "if crop_checkbox:\n",
        "    transforms_array_train.append(transforms.RandomCrop(padding=None, size=(input_size, input_size)))\n",
        "if translation_checkbox:\n",
        "    transforms_array_train.append(transforms.RandomAffine(0, (0.2, 0.2)))\n",
        "if flip_checkbox:\n",
        "    transforms_array_train.append(transforms.RandomHorizontalFlip(p=0.5))\n",
        "if rotation_checkbox:\n",
        "    transforms_array_train.append(transforms.RandomRotation(degrees=(-15,15), resample=False, expand=False))\n",
        "if color_checkbox:\n",
        "    transforms_array_train.append(transforms.ColorJitter(brightness=[0.8,1.2], contrast=[0.8,1.2], saturation=[0.8,1.2]))\n",
        "if noise_checkbox:\n",
        "    transforms_array_train.append(AddGaussianNoise(0., 0.2))\n",
        "\n",
        "transforms_array_train.append(transforms.ToTensor())\n",
        "transforms_array_test = []\n",
        "\n",
        "if config == \"Pretrained VGG16\" or config == \"GoogLeNet\":\n",
        "    transforms_array_train.append(transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                std=[0.229, 0.224, 0.225]))\n",
        "    transforms_array_test.append(transforms.Resize(size=(input_size, input_size)))\n",
        "    transforms_array_test.append(transforms.ToTensor())\n",
        "    transforms_array_test.append(transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                std=[0.229, 0.224, 0.225]))\n",
        "else:\n",
        "    transforms_array_train.append(transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)))\n",
        "    transforms_array_test.append(transforms.ToTensor())\n",
        "    transforms_array_test.append(transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgDB0MJEyLUv",
        "colab_type": "text"
      },
      "source": [
        "## Wczytanie danych"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23wbllWBNfEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform_train = transforms.Compose(transforms_array_train)\n",
        "transform_test = transforms.Compose(transforms_array_test)\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SeGEuKv9h620",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(testloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(10)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1Zt3tB75fcR",
        "colab_type": "text"
      },
      "source": [
        "## Zapis stanu modelu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMj0iZ3oacsW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from datetime import datetime\n",
        "\n",
        "def append_timestamp(path):\n",
        "    now = datetime.now()\n",
        "    current_time = now.strftime(\"%y.%m.%d_%H:%M:%S\")\n",
        "    return path.replace(\".\", f\"_{current_time}.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3IHZ3gd5joY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_state = True #@param {type: \"boolean\"}\n",
        "best_path = \"komitet.pt\" #@param {type: \"string\"}\n",
        "use_timestamp = False #@param {type: \"boolean\"}\n",
        "\n",
        "def save_model(path):\n",
        "    if save_state:\n",
        "        if use_timestamp:\n",
        "            best_path = append_timestamp(path)\n",
        "        torch.save({\n",
        "                    'epoch': last_epoch,\n",
        "                    'model_state_dict': net.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    'criterion_state_dict': criterion.state_dict(),\n",
        "                    'loss': last_loss,\n",
        "                    'loss_array': loss_array,\n",
        "                    'acc_array': acc_array\n",
        "                    }, BASE_DIR + path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lr82fiblseX7",
        "colab_type": "text"
      },
      "source": [
        "## Uczenie sieci"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNk0QD6ytHSR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def update_classify_table(classify_table, predictions, labels):\n",
        "        for lab, pred in zip(labels, predictions):\n",
        "            classify_table[lab, pred] += 1\n",
        "\n",
        "def train_step(last_epoch):\n",
        "    running_loss = 0.0\n",
        "    for i, (img, label) in enumerate(trainloader):\n",
        "        img = img.to(device)\n",
        "        label = label.to(device)\n",
        "        net.train()\n",
        "        optimizer.zero_grad()\n",
        "        prediction = net(img)\n",
        "        loss = None\n",
        "        if config == \"Zmodyfikowany LeNet-5\" or config == \"Wlasna konfiguracja 1\":\n",
        "            loss = criterion(prediction[0], label)\n",
        "        else:\n",
        "            loss = criterion(prediction, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if config == \"Zmodyfikowany LeNet-5\" or config == \"Wlasna konfiguracja 1\":\n",
        "            running_loss += loss.item()\n",
        "        else:\n",
        "            running_loss += loss.item() * img.size(0)\n",
        "    return running_loss\n",
        "    \n",
        "\n",
        "def print_accuracy():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        net.eval()\n",
        "        classify_table = np.zeros((10,10))\n",
        "        for i, (img, label) in enumerate(testloader):\n",
        "            img = img.to(device)\n",
        "            label = label.to(device)\n",
        "            prediction = net(img)\n",
        "            if config == \"Zmodyfikowany LeNet-5\" or config == \"Wlasna konfiguracja 1\":\n",
        "                loss += criterion(prediction[0], label)\n",
        "                _ , prediction = torch.max(prediction[0].data, 1)\n",
        "            else:\n",
        "                loss += criterion(prediction, label)\n",
        "                _ , prediction = torch.max(prediction.data, 1)\n",
        "            update_classify_table(classify_table, prediction, label.data)\n",
        "            correct += torch.sum(prediction == label.data)\n",
        "\n",
        "    accuracy = correct.cpu().numpy() / 10000\n",
        "    print('Accuracy of the network on the 10000 test images: %.2f %%' % (\n",
        "        100 * accuracy))   \n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YS0hPb22b6cw",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "nb_epoch =  10#@param {type: \"integer\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqjQfl713qAU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "counter = 0\n",
        "\n",
        "for e in range(nb_epoch):\n",
        "    last_epoch = last_epoch + 1\n",
        "    running_loss = train_step(last_epoch)\n",
        "    if config == \"Zmodyfikowany LeNet-5\" or config == \"Wlasna konfiguracja 1\":\n",
        "        last_loss = running_loss / 500\n",
        "    else:\n",
        "        last_loss = running_loss / len(trainloader.dataset)\n",
        "    print('%d epoch, loss: %.4f' % (last_epoch, last_loss))\n",
        "    loss_array.append(last_loss)\n",
        "    curr_acc = print_accuracy()\n",
        "    acc_array.append(curr_acc)\n",
        "    if curr_acc > max_acc:\n",
        "        save_model(best_path)\n",
        "        max_acc = curr_acc\n",
        "        counter = 0\n",
        "    else:\n",
        "        counter = counter + 1\n",
        "        if counter > 2:\n",
        "            break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nyTlBZP9olO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_model(best_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUqZ4rjhqh_H",
        "colab_type": "text"
      },
      "source": [
        "### Wczytanie najlepszego stanu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFcUPgqUq0Fh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "load_best = True #@param {type: \"boolean\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bW1BrCUxoGe-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if save_state and load_best:\n",
        "    load_net_state(BASE_DIR + best_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9LdyoFI_yzP",
        "colab_type": "text"
      },
      "source": [
        "## Komitet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rct7zuMk_0_N",
        "colab_type": "text"
      },
      "source": [
        "### Budowa komitetu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znOx-64s_3tS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyEnsemble(nn.Module):\n",
        "    def __init__(self, modelA, modelB, modelC, modelD, modelE, modelF, modelG, modelH, modelI, modelJ, nb_classes=10):\n",
        "        super(MyEnsemble, self).__init__()\n",
        "        self.modelA = modelA\n",
        "        self.modelB = modelB\n",
        "        self.modelC = modelC\n",
        "        self.modelD = modelD\n",
        "        self.modelE = modelE\n",
        "        self.modelF = modelF\n",
        "        self.modelG = modelG\n",
        "        self.modelH = modelH\n",
        "        self.modelI = modelI\n",
        "        self.modelJ = modelJ\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x1 = self.modelA(x.clone())\n",
        "        x2 = self.modelB(x)\n",
        "        x3 = self.modelC(x)\n",
        "        x4 = self.modelD(x)\n",
        "        x5 = self.modelE(x)\n",
        "        x6 = self.modelF(x)\n",
        "        x7 = self.modelG(x)\n",
        "        x8 = self.modelH(x)\n",
        "        x9 = self.modelI(x)\n",
        "        x10 = self.modelJ(x)\n",
        "        x = torch.stack((x1, x2, x3, x4, x5, x6, x7, x8, x9, x10), dim=1)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUuijs6JSxhw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model():\n",
        "    if config == \"Pretrained VGG16\":\n",
        "        net = models.vgg16_bn(pretrained=True)\n",
        "        num_ftrs = net.fc.in_features\n",
        "        net.fc = nn.Linear(num_ftrs, 10)\n",
        "    elif config == \"GoogLeNet\":\n",
        "        net = models.googlenet(pretrained=True)\n",
        "        num_ftrs = net.fc.in_features\n",
        "        net.fc = nn.Linear(num_ftrs, 10)\n",
        "    else:\n",
        "        net = Net()\n",
        "    return net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwCCJwrYAI6y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelA = create_model().to(device)\n",
        "checkpointA = torch.load((BASE_DIR + 'GoogLeNet-pełny/best.pt'))\n",
        "modelA.load_state_dict(checkpointA['model_state_dict'])\n",
        "\n",
        "modelB = create_model().to(device)\n",
        "checkpointB = torch.load((BASE_DIR + 'GoogLeNet-pełny/best_1.pt'))\n",
        "modelB.load_state_dict(checkpointB['model_state_dict'])\n",
        "\n",
        "modelC = create_model().to(device)\n",
        "checkpointC = torch.load((BASE_DIR + 'GoogLeNet-pełny/best_2.pt'))\n",
        "modelC.load_state_dict(checkpointC['model_state_dict'])\n",
        "\n",
        "modelD = create_model().to(device)\n",
        "checkpointD = torch.load((BASE_DIR + 'GoogLeNet-pełny/best_3.pt'))\n",
        "modelD.load_state_dict(checkpointD['model_state_dict'])\n",
        "\n",
        "modelE = create_model().to(device)\n",
        "checkpointE = torch.load((BASE_DIR + 'GoogLeNet-pełny/best_4.pt'))\n",
        "modelE.load_state_dict(checkpointE['model_state_dict'])\n",
        "\n",
        "modelF = create_model().to(device)\n",
        "checkpointF = torch.load((BASE_DIR + 'GoogLeNet-pełny/best_5.pt'))\n",
        "modelF.load_state_dict(checkpointF['model_state_dict'])\n",
        "\n",
        "modelG = create_model().to(device)\n",
        "checkpointG = torch.load((BASE_DIR + 'best_6.pt'))\n",
        "modelG.load_state_dict(checkpointG['model_state_dict'])\n",
        "\n",
        "modelH = create_model().to(device)\n",
        "checkpointH = torch.load((BASE_DIR + 'best_7.pt'))\n",
        "modelH.load_state_dict(checkpointH['model_state_dict'])\n",
        "\n",
        "modelI = create_model().to(device)\n",
        "checkpointI = torch.load((BASE_DIR + 'best_8.pt'))\n",
        "modelI.load_state_dict(checkpointI['model_state_dict'])\n",
        "\n",
        "modelJ = create_model().to(device)\n",
        "checkpointJ = torch.load((BASE_DIR + 'best_9.pt'))\n",
        "modelJ.load_state_dict(checkpointJ['model_state_dict'])\n",
        "\n",
        "model = MyEnsemble(modelA, modelB, modelC, modelD, modelE, modelF, modelG, modelH, modelI, modelJ).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5C12b4diD2n",
        "colab_type": "text"
      },
      "source": [
        "### Wyniki dla komitetu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKellF04XsQd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    classify_table = np.zeros((10,10))\n",
        "    for i, (img, label) in enumerate(testloader):\n",
        "        img = img.to(device)\n",
        "        label = label.to(device)\n",
        "        prediction = model(img)\n",
        "        predictions = []\n",
        "        if config != \"GoogLeNet\":\n",
        "            for p in prediction[0]:\n",
        "                _, curr_pred = torch.max(p.data, 1)\n",
        "                predictions.append(curr_pred)\n",
        "            prediction_list = []\n",
        "            for j in range(100):\n",
        "                tab = np.zeros(10)\n",
        "                for k in range(10):\n",
        "                    tab[predictions[k][j]] = tab[predictions[k][j]] + 1\n",
        "                max_pred = tab.max()\n",
        "                max_count = 0\n",
        "                for k in range(10):\n",
        "                    if tab[k] == max_pred:\n",
        "                        max_count = max_count + 1\n",
        "                if max_count == 1:\n",
        "                    prediction_list.append(tab.argmax())\n",
        "                else:\n",
        "                    prediction_list.append(predictions[4][j])\n",
        "        else:\n",
        "            for p in prediction:\n",
        "                _, curr_pred = torch.max(p.data, 1)\n",
        "                predictions.append(curr_pred)\n",
        "            prediction_list = []\n",
        "            for j in range(100):\n",
        "                tab = np.zeros(10)\n",
        "                for k in range(10):\n",
        "                    tab[predictions[j][k]] = tab[predictions[j][k]] + 1\n",
        "                max_pred = tab.max()\n",
        "                max_count = 0\n",
        "                for k in range(10):\n",
        "                    if tab[k] == max_pred:\n",
        "                        max_count = max_count + 1\n",
        "                if max_count == 1:\n",
        "                    prediction_list.append(tab.argmax())\n",
        "                else:\n",
        "                    prediction_list.append(predictions[j][7])\n",
        "        prediction = torch.FloatTensor(prediction_list).to(device)\n",
        "        update_classify_table(classify_table, prediction_list, label.data)\n",
        "        correct += torch.sum(prediction == label.data)\n",
        "\n",
        "accuracy = correct.cpu().numpy() / 10000\n",
        "print('Accuracy of the network on the 10000 test images: %.2f %%' % (\n",
        "    100 * accuracy)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVzNqlh92IL0",
        "colab_type": "text"
      },
      "source": [
        "## Wyniki"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zleCjE2NOFs5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "loss = 0.0\n",
        "with torch.no_grad():\n",
        "    modelA.eval()\n",
        "    classify_table = np.zeros((10,10))\n",
        "    for i, (img, label) in enumerate(testloader):\n",
        "        img = img.to(device)\n",
        "        label = label.to(device)\n",
        "        prediction = modelA(img)\n",
        "        if config == \"Zmodyfikowany LeNet-5\" or config == \"Wlasna konfiguracja 1\":\n",
        "            loss += criterion(prediction[0], label)\n",
        "            _ , prediction = torch.max(prediction.data, 1)\n",
        "        else:\n",
        "            loss += criterion(prediction, label)\n",
        "            _ , prediction = torch.max(prediction.data, 1)\n",
        "\n",
        "        update_classify_table(classify_table, prediction, label.data)\n",
        "        correct += torch.sum(prediction == label.data)\n",
        "\n",
        "accuracy = correct.cpu().numpy() / 10000\n",
        "print('Accuracy of the network on the 10000 test images: %.2f %%' % (\n",
        "    100 * accuracy)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZ_bbCQBY4ML",
        "colab_type": "text"
      },
      "source": [
        "## Wykresy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OsDHNGBY5P2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = range(1, last_epoch + 1)\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "ax.set_xticks(np.arange(0, last_epoch + 1, 1))\n",
        "\n",
        "plt.scatter(epochs, loss_array)\n",
        "plt.title(\"Wykres funkcji straty dla zbioru treningowego\")\n",
        "plt.xlabel(\"Numer epoki\")\n",
        "plt.ylabel(\"Wartość funkcji straty\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_lxILwc9Npd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = range(1, last_epoch + 1)\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "ax.set_xticks(np.arange(0, last_epoch + 1))\n",
        "\n",
        "plt.scatter(epochs, acc_array)\n",
        "plt.title(\"Wykres dokładności dla zbioru walidacyjnego\")\n",
        "plt.xlabel(\"Numer epoki\")\n",
        "plt.ylabel(\"Dokładność\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9N0b7Eq3MN-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import copy\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "    \n",
        "def visualise_accuracy_by_class(classify_table):\n",
        "    results = [ classify_table[i,i] / np.sum(classify_table[i, :]) for i in range(10)]\n",
        "\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_axes([0,0,1,1])\n",
        "\n",
        "    plt.bar(classes, results, color = ['#7e57c2', '#ffc400'])\n",
        "    plt.title(\"Frakcja poprawnych klasyfikacji dla poszczególnych klas\")\n",
        "    plt.xlabel('Klasa')\n",
        "    plt.ylabel('Frakcja poprawnych klasyfikacji')\n",
        "    plt.xticks(classes)\n",
        "    plt.show()\n",
        "    \n",
        "def visualise_errors_by_class(classify_table):\n",
        "    p = list()\n",
        "    table = copy.deepcopy(classify_table)\n",
        "    table[np.argmax(table, 0), np.argmax(table, 1)] = 0\n",
        "    p.append(plt.bar(classes, table[:, 0]))\n",
        "    for i in range(1, 10):\n",
        "        p.append(plt.bar(classes, table[:, i], bottom = np.sum(table[:, 0:i], 1)))\n",
        "\n",
        "    plt.title(\"Błędy klasyfikacji\")\n",
        "    plt.xticks(classes)\n",
        "    plt.xlabel(\"Poprawna klasa\")\n",
        "    plt.ylabel(\"Liczba błędnych klasyfikacji\")\n",
        "    plt.legend(classes, title = \"Klasa zwracana przez sieć\", bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
        "    plt.show()\n",
        "\n",
        "def visualise_errors_for_class(classify_table, class_index):\n",
        "    p = list()\n",
        "    table = copy.deepcopy(classify_table)\n",
        "    table[np.argmax(table, 0), np.argmax(table, 1)] = 0\n",
        "\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_axes([0,0,1,1])\n",
        "\n",
        "    plt.bar(classes, table[:, class_index])\n",
        "    plt.xticks(classes)\n",
        "    plt.title(\"Liczba błędnych klasyfikacji dla klasy: {}\".format(classes[class_index]))\n",
        "    plt.xlabel(\"Klasa zwracana przez sieć\")\n",
        "    plt.ylabel(\"Liczba błędnych klasyfikacji\")\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLHPRXQg3Sxs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "visualise_accuracy_by_class(classify_table)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LChXagfO3vl9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "visualise_errors_by_class(classify_table)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4A8cUhQ5LxX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "visualise_errors_for_class(classify_table, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}